{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/zhc268/data/projects/')\n",
    "import OrbWeaver\n",
    "# additional libs\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "\n",
    "# import libs for numerical ops\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# optimizer for neural net\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "# custom libs\n",
    "import callbacks\n",
    "from  model import *\n",
    "import load\n",
    "\n",
    "from learn_parameters import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(genome='genome/hg19.fa', log_file='./log.txt', model_prefix='test', num_epochs=100, peak_file='./testdata/test_openchromatin_windows.bed.gz', prediction_type='celltype', pwms='pwms', test_chromosome='chr18', window_size=500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"OrbWeaver learns \"\n",
    "    \"a neural network model that predicts the open chromatin state of \"\n",
    "    \"a genomic locus across multiple cell types based on its DNA sequence alone.\")\n",
    "\n",
    "parser.add_argument(\"--peak_file\",\n",
    "                    action=\"store\",\n",
    "                    help=\"name of a gzipped text file containing \"\n",
    "                    \" positional information of genomic loci that are active in at least \"\n",
    "                    \" one cell type, and their chromatin activity across all cell types. \"\n",
    "                    \" columns of the file should be as follows. \"\n",
    "                    \" Chromosome Start End CellType1_Activity CellType2_Activity ... \")\n",
    "\n",
    "parser.add_argument(\"--window_size\",\n",
    "                    type=int,\n",
    "                    default=500,\n",
    "                    help=\"length of DNA sequence centered at each genomic locus \"\n",
    "                    \"used for making predictions. (default: 500)\")\n",
    "\n",
    "parser.add_argument(\"--test_chromosome\",\n",
    "                    type=str,\n",
    "                    default=\"chr18\",\n",
    "                    help=\"chromosome to be held out as test data, \"\n",
    "                    \"to evaluate the performance of the final model (default: chr18)\")\n",
    "\n",
    "parser.add_argument(\"--model_prefix\",\n",
    "                    type=str,\n",
    "                    default=None,\n",
    "                    help=\"prefix of file name to store the architecture and \"\n",
    "                    \"parameters of the neural network\")\n",
    "\n",
    "parser.add_argument(\"--log_file\",\n",
    "                    type=str,\n",
    "                    default=None,\n",
    "                    help=\"file name to log output of the software\")\n",
    "\n",
    "parser.add_argument(\"--pwms\",\n",
    "                    type=str,\n",
    "                    default=\"pwms\",\n",
    "                    help=\"path to files with position weight matrices, \"\n",
    "                    \"one per transcription factor or genomic feature \")\n",
    "\n",
    "parser.add_argument(\"--genome\",\n",
    "                    type=str,\n",
    "                    default=\"genome/hg19.fa\",\n",
    "                    help=\"path to indexed fasta file containing the relevant \"\n",
    "                    \"reference genome sequence\")\n",
    "\n",
    "parser.add_argument(\"--prediction_type\",\n",
    "                    type=str,\n",
    "                    default=\"celltype\",\n",
    "                    help=\"specify whether the predicted output should be chromatin activity \"\n",
    "                    \"in a specific cell type or a group of cell types. groups are restricted \"\n",
    "                    \"to subsets of cells in which the chromatin is open in all cells in the \"\n",
    "                    \"subset (and closed in all others) at least 1000 genomic loci. \"\n",
    "                    \"(default: cellgroup, options: celltype/cellgroup)\")\n",
    "\n",
    "parser.add_argument(\"--num_epochs\",\n",
    "                    type=int,\n",
    "                    default=100,\n",
    "                    help=\"each iteration of stochastic gradient descent uses 100 loci to compute the \"\n",
    "                    \"gradient, and each epoch (when the validation error is evaluated) consists of \"\n",
    "                    \"10000 loci. this parameter specifies the max number of epochs to run the algorithm. \"\n",
    "                    \"if the data set has a large number of loci, increase this parameter to include at least \"\n",
    "                    \"one pass through the data. \")\n",
    "\n",
    "options = parser.parse_args([\n",
    "    '--peak_file', './testdata/test_openchromatin_windows.bed.gz',\n",
    "    '--log_file', './log.txt','--model_prefix','test'\n",
    "])\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak file: ./testdata/test_openchromatin_windows.bed.gz\n",
      "test chromosome: chr18\n",
      "prediction type: celltype\n",
      "['iPSC', 'LCL', 'iPSC-CM']\n",
      "number of training sites: 279191\n",
      "number of testing sites: 7151\n",
      "number of validation sites: 2897\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(options.log_file)\n",
    "logger.log_this(\"peak file: %s\"%options.peak_file)\n",
    "logger.log_this(\"test chromosome: %s\"%options.test_chromosome)\n",
    "logger.log_this(\"prediction type: %s\"%options.prediction_type)\n",
    "\n",
    "\n",
    "training, validation, test, cellnames = load.partition_sites(options)\n",
    "\n",
    "\n",
    "logger.log_this(\"number of training sites: %d\"%len(training))\n",
    "logger.log_this(\"number of testing sites: %d\"%len(test))\n",
    "logger.log_this(\"number of validation sites: %d\"%len(validation))\n",
    "\n",
    "if options.prediction_type==\"cellgroup\":\n",
    "    logger.log_this(\"identifying cell groups from observed open chromatin activity ...\")\n",
    "    cellgroup_mappings, cellgroup_map_array = load.map_cellgroup_to_category(options.peak_file)\n",
    "else:\n",
    "    cellgroup_mappings = None\n",
    "    cellgroup_map_array = None\n",
    "\n",
    "# load reference genome track\n",
    "genome_track = load.Genome(options.genome, options.prediction_type, cellgroup_mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up a generator for training data ...\n",
      "loading validation data ...\n"
     ]
    }
   ],
   "source": [
    "# training data generator\n",
    "logger.log_this(\"setting up a generator for training data ...\")\n",
    "train_data_generator = load.DataGenerator(training, genome_track)\n",
    "train_flow = train_data_generator.flow(batch_size=100)\n",
    "\n",
    "# validation data\n",
    "logger.log_this(\"loading validation data ...\")\n",
    "validation_data_generator = load.DataGenerator(validation, genome_track)\n",
    "valid_flow = validation_data_generator.flow(batch_size=len(validation))\n",
    "X_validation, Y_validation = valid_flow.next()\n",
    "N_outputs = Y_validation.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the OrbWeaver model ...\n"
     ]
    }
   ],
   "source": [
    "# construct model\n",
    "logger.log_this(\"building the OrbWeaver model ...\")\n",
    "if options.prediction_type=='celltype':\n",
    "    output_activation = 'sigmoid'\n",
    "    loss = 'binary_crossentropy'\n",
    "elif options.prediction_type=='cellgroup':\n",
    "    output_activation = 'softmax'\n",
    "    loss = 'categorical_crossentropy'\n",
    "\n",
    "network, tfs = model.build_neural_network(N_outputs, output_activation, options.pwms, options.window_size)     \n",
    "#def build_neural_network(num_outputs, output_activation, path_to_pwms, window_size):\n",
    "\n",
    "#N_outputs,output_activation,options.pwms,options.window_size\n",
    "\n",
    "#pwms, tfs = get_pwms(options.pwms)\n",
    "#P, ig, L = pwms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "1. http://cs231n.github.io/convolutional-networks/#conv to demonstrate dimension changes\n",
    "\n",
    "Accepts a volume of size W1×H1×D1\n",
    "Requires four hyperparameters:\n",
    "- Number of filters K,\n",
    "- their spatial extent F,\n",
    "- the stride S, (move number of pixals for each filter)\n",
    "- the amount of zero padding P.\n",
    "\n",
    "Produces a volume of size W2×H2×D2 where:\n",
    "- W2=(W1−F+2P)/S+1\n",
    "- H2=(H1−F+2P)/S+1 (i.e. width and height are computed equally by symmetry)\n",
    "- D2=K\n",
    "\n",
    "With parameter sharing, it introduces F⋅F⋅D1 weights per filter, for a total of (F⋅F⋅D1)⋅K weights and K biases.\n",
    "In the output volume, the d-th depth slice (of size W2×H2) is the result of performing a valid convolution of the d-th filter over the input volume with a stride of S, and then offset by d-th bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling the OrbWeaver model ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set optimization parameters\n",
    "logger.log_this(\"compiling the OrbWeaver model ...\")\n",
    "network.compile(optimizer=Adadelta(), \n",
    "                loss=loss,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "import pdb\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "class AuROC(Callback):\n",
    "\n",
    "    def __init__(self, predtype, map_array, logger):\n",
    "\n",
    "        self.prediction_type = predtype\n",
    "        self.map_array = map_array\n",
    "        self.logger = logger\n",
    "        self.current_time = time.time()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.values = []\n",
    "        self.current_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        values = []\n",
    "        prediction = self.model.predict(self.validation_data[0])\n",
    "        Y = self.validation_data[1]\n",
    "        import pdb; pdb.set_trace()\n",
    "        \n",
    "        if self.prediction_type==\"cellgroup\":\n",
    "            prediction = np.dot(prediction, self.map_array)\n",
    "            Y = np.dot(Y, self.map_array)\n",
    "        \n",
    "\n",
    "\n",
    "        mask = ~np.logical_or(Y.sum(1)==0, Y.sum(1)==Y.shape[1])\n",
    "\n",
    "        \n",
    "        for y,pred in zip(Y.T,prediction.T):\n",
    "            pos = np.logical_and(mask, y==1)\n",
    "            neg = np.logical_and(mask, y==0)\n",
    "            try:\n",
    "                U = stats.mannwhitneyu(pred[pos], pred[neg])[0]\n",
    "                values.append(1.-U/(np.count_nonzero(pos)*np.count_nonzero(neg)))\n",
    "            except ValueError:\n",
    "                values.append(0.5)\n",
    "\n",
    "        self.values.append(values)\n",
    "        epoch_time = time.time()-self.current_time\n",
    "        self.logger.log_this(\"epoch_%d_auroc: %s (%ds)\"%(epoch, ' '.join(['%.4f'%v for v in self.values[-1]]), int(epoch_time)))\n",
    "        self.current_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pydot' from '/projects/ps-epigen/software/miniconda3/envs/scanpy/lib/python3.6/site-packages/pydot.py'>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras' from '/projects/ps-epigen/software/miniconda3/envs/scanpy/lib/python3.6/site-packages/keras/__init__.py'>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "reload(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-815d047014ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#import pydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_plot.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/ps-epigen/software/miniconda3/envs/scanpy/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/ps-epigen/software/miniconda3/envs/scanpy/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/ps-epigen/software/miniconda3/envs/scanpy/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "#import pydot\n",
    "plot_model(network, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 1, 472, 2554)      298818    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 118, 2554)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 113, 200)       3065000   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 37, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               3700500   \n",
      "_________________________________________________________________\n",
      "gaussian_dropout_1 (Gaussian (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 7,065,821\n",
      "Trainable params: 6,767,003\n",
      "Non-trainable params: 298,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the OrbWeaver model ...\n",
      "cell types: iPSC LCL iPSC-CM\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ps-epigen/software/miniconda3/envs/scanpy/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<load.Data..., epochs=100, verbose=1, validation_data=(array([[[..., callbacks=[<callback..., steps_per_epoch=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 50s 10s/step - loss: 0.3899 - acc: 0.8253 - val_loss: 0.4125 - val_acc: 0.8172\n",
      "epoch_0_auroc: 0.8876 0.7031 0.7905 (100s)\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.4095 - acc: 0.8087 - val_loss: 0.3939 - val_acc: 0.8303\n",
      "epoch_1_auroc: 0.8875 0.7606 0.7965 (100s)\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.3953 - acc: 0.8253 - val_loss: 0.3829 - val_acc: 0.8320\n",
      "epoch_2_auroc: 0.8875 0.7242 0.8383 (106s)\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.4217 - acc: 0.8127 - val_loss: 0.3843 - val_acc: 0.8325\n",
      "epoch_3_auroc: 0.8882 0.7224 0.8290 (100s)\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.4265 - acc: 0.8020 - val_loss: 0.3804 - val_acc: 0.8310\n",
      "epoch_4_auroc: 0.8924 0.7367 0.8220 (100s)\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.4164 - acc: 0.8180 - val_loss: 0.3806 - val_acc: 0.8324\n",
      "epoch_5_auroc: 0.8911 0.7361 0.8128 (100s)\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.3982 - acc: 0.8313 - val_loss: 0.4046 - val_acc: 0.8194\n",
      "epoch_6_auroc: 0.8888 0.7477 0.7938 (100s)\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.4284 - acc: 0.8087 - val_loss: 0.3896 - val_acc: 0.8281\n",
      "epoch_7_auroc: 0.8884 0.7517 0.7717 (100s)\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.3929 - acc: 0.8227 - val_loss: 0.3909 - val_acc: 0.8275\n",
      "epoch_8_auroc: 0.8864 0.7826 0.7626 (100s)\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.3963 - acc: 0.8180 - val_loss: 0.3922 - val_acc: 0.8265\n",
      "epoch_9_auroc: 0.8845 0.7463 0.8056 (100s)\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.3691 - acc: 0.8393 - val_loss: 0.3833 - val_acc: 0.8295\n",
      "epoch_10_auroc: 0.8892 0.7275 0.8346 (100s)\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 50s 10s/step - loss: 0.4108 - acc: 0.8213 - val_loss: 0.4032 - val_acc: 0.8205\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload  # Python 3.4+ only.\n",
    "\n",
    "load=reload(callbacks)\n",
    "\n",
    "# callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "auroc = callbacks.AuROC(options.prediction_type, cellgroup_map_array, logger)\n",
    "\n",
    "\n",
    "# train model\n",
    "logger.log_this(\"training the OrbWeaver model ...\")\n",
    "logger.log_this(\"cell types: %s\"%(' '.join(cellnames)))\n",
    "history = network.fit_generator(train_flow, \\\n",
    "                                samples_per_epoch=5, \\\n",
    "                                epochs=options.num_epochs, \\\n",
    "                                verbose=1, \\\n",
    "                                validation_data=(X_validation, Y_validation), \\\n",
    "                                callbacks=[auroc, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'load' from '/projects/ps-epigen/projects/OrbWeaver/load.py'>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import load\n",
    "reload(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data ...\n"
     ]
    }
   ],
   "source": [
    "# evaluate test accuracy\n",
    "from importlib import reload  # Python 3.4+ only.\n",
    "\n",
    "load=reload(load)\n",
    "logger.log_this(\"loading test data ...\")\n",
    "test_data_generator = load.DataGenerator(test, genome_track)\n",
    "\n",
    "test_flow = test_data_generator.flow(batch_size=len(test))\n",
    "X_test, Y_test = test_flow.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model on test data ...\n",
      "test auroc: 0.8598 0.7337 0.8294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.log_this(\"evaluating model on test data ...\")\n",
    "test_auc = compute_test_accuracy(X_test, Y_test, network, options.prediction_type, cellgroup_map_array)\n",
    "logger.log_this(\"test auroc: %s\"%(' '.join(['%.4f'%v for v in test_auc])))\n",
    "\n",
    "genome_track.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model architecture and parameters ...\n"
     ]
    }
   ],
   "source": [
    "logger.log_this(\"saving the model architecture and parameters ...\")\n",
    "# save model architecture\n",
    "network_arch = network.to_json()\n",
    "handle = open(\"%s.json\"%options.model_prefix,'w')\n",
    "handle.write(network_arch)\n",
    "handle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# save model parameters\n",
    "network.save_weights(\"%s.h5\"%options.model_prefix, overwrite=True)\n",
    "\n",
    "\n",
    "# save TFs\n",
    "his = history.history\n",
    "handle = open(\"%s.tfs.pkl\"%options.model_prefix,'wb')\n",
    "pickle.dump(tfs,handle,protocol=2)\n",
    "pickle.dump(history.history,handle,protocol=2)\n",
    "pickle.dump(test_auc,handle,protocol=2)\n",
    "handle.close()\n",
    "\n",
    "logger.log_this(\"done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
